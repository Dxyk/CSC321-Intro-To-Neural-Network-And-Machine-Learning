{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-56268d4d9dac>\", line 15, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/anaconda3/envs/Python2.7/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.misc\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "from load_data import load_cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Agg')  # switch backend\n",
    "\n",
    "HORSE_CATEGORY = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = False\n",
    "valid = False\n",
    "# checkpoint = \"\"\n",
    "checkpoint = \"unet_k3_f32.pkl\"\n",
    "plot = False\n",
    "colours = \"colours/colour_kmeans24_cat7.npy\"\n",
    "model = \"UNet\"\n",
    "kernel = 3\n",
    "num_filters = 32\n",
    "learn_rate = 0.001\n",
    "# batch_size = 100\n",
    "batch_size = 10\n",
    "# epochs = 25\n",
    "epochs = 5\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Data related code\n",
    "######################################################################\n",
    "def get_rgb_cat(xs, colours):\n",
    "    \"\"\"\n",
    "    Get colour categories given RGB values. This function doesn't\n",
    "    actually do the work, instead it splits the work into smaller\n",
    "    chunks that can fit into memory, and calls helper function\n",
    "    _get_rgb_cat\n",
    "\n",
    "    Args:\n",
    "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      result: int numpy array of shape [B, 1, H, W]\n",
    "    \"\"\"\n",
    "    if np.shape(xs)[0] < 100:\n",
    "        return _get_rgb_cat(xs)\n",
    "    batch_size = 100\n",
    "    nexts = []\n",
    "    for i in range(0, np.shape(xs)[0], batch_size):\n",
    "        next = _get_rgb_cat(xs[i:i + batch_size, :, :, :], colours)\n",
    "        nexts.append(next)\n",
    "    result = np.concatenate(nexts, axis = 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_rgb_cat(xs, colours):\n",
    "    \"\"\"\n",
    "    Get colour categories given RGB values. This is done by choosing\n",
    "    the colour in `colours` that is the closest (in RGB space) to\n",
    "    each point in the image `xs`. This function is a little memory\n",
    "    intensive, and so the size of `xs` should not be too large.\n",
    "\n",
    "    Args:\n",
    "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      result: int numpy array of shape [B, 1, H, W]\n",
    "    \"\"\"\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    xs = np.expand_dims(xs, 0)\n",
    "    cs = np.reshape(colours, [num_colours, 1, 3, 1, 1])\n",
    "    dists = np.linalg.norm(xs - cs, axis = 2)  # 2 = colour axis\n",
    "    cat = np.argmin(dists, axis = 0)\n",
    "    cat = np.expand_dims(cat, axis = 1)\n",
    "    return cat\n",
    "\n",
    "\n",
    "def get_cat_rgb(cats, colours):\n",
    "    \"\"\"\n",
    "    Get RGB colours given the colour categories\n",
    "\n",
    "    Args:\n",
    "      cats: integer numpy array of colour categories\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      numpy tensor of RGB colours\n",
    "    \"\"\"\n",
    "    return colours[cats]\n",
    "\n",
    "\n",
    "def process(xs, ys, max_pixel = 256.0):\n",
    "    \"\"\"\n",
    "    Pre-process CIFAR10 images by taking only the horse category,\n",
    "    shuffling, and have colour values be bound between 0 and 1\n",
    "\n",
    "    Args:\n",
    "      xs: the colour RGB pixel values\n",
    "      ys: the category labels\n",
    "      max_pixel: maximum pixel value in the original data\n",
    "    Returns:\n",
    "      xs: value normalized and shuffled colour images\n",
    "      grey: greyscale images, also normalized so values are between 0 and 1\n",
    "    \"\"\"\n",
    "    xs = xs / max_pixel\n",
    "    xs = xs[np.where(ys == HORSE_CATEGORY)[0], :, :, :]\n",
    "    npr.shuffle(xs)\n",
    "    grey = np.mean(xs, axis = 1, keepdims = True)\n",
    "    return (xs, grey)\n",
    "\n",
    "\n",
    "def get_batch(x, y, batch_size):\n",
    "    '''\n",
    "    Generated that yields batches of data\n",
    "\n",
    "    Args:\n",
    "      x: input values\n",
    "      y: output values\n",
    "      batch_size: size of each batch\n",
    "    Yields:\n",
    "      batch_x: a batch of inputs of size at most batch_size\n",
    "      batch_y: a batch of outputs of size at most batch_size\n",
    "    '''\n",
    "    N = np.shape(x)[0]\n",
    "    assert N == np.shape(y)[0]\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_x = x[i:i + batch_size, :, :, :]\n",
    "        batch_y = y[i:i + batch_size, :, :, :]\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "\n",
    "def plot(input, gtlabel, output, colours, path):\n",
    "    \"\"\"\n",
    "    Generate png plots of input, ground truth, and outputs\n",
    "\n",
    "    Args:\n",
    "      input: the greyscale input to the colourization CNN\n",
    "      gtlabel: the grouth truth categories for each pixel\n",
    "      output: the predicted categories for each pixel\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "      path: output path\n",
    "    \"\"\"\n",
    "    grey = np.transpose(input[:10, :, :, :], [0, 2, 3, 1])\n",
    "    gtcolor = get_cat_rgb(gtlabel[:10, 0, :, :], colours)\n",
    "    predcolor = get_cat_rgb(output[:10, 0, :, :], colours)\n",
    "\n",
    "    img = np.vstack([\n",
    "        np.hstack(np.tile(grey, [1, 1, 1, 3])),\n",
    "        np.hstack(gtcolor),\n",
    "        np.hstack(predcolor)])\n",
    "    scipy.misc.toimage(img, cmin = 0, cmax = 1).save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Torch Helper\n",
    "######################################################################\n",
    "\n",
    "def get_torch_vars(xs, ys, gpu = False):\n",
    "    \"\"\"\n",
    "    Helper function to convert numpy arrays to pytorch tensors.\n",
    "    If GPU is used, move the tensors to GPU.\n",
    "\n",
    "    Args:\n",
    "      xs (float numpy tenosor): greyscale input\n",
    "      ys (int numpy tenosor): categorical labels\n",
    "      gpu (bool): whether to move pytorch tensor to GPU\n",
    "    Returns:\n",
    "      Variable(xs), Variable(ys)\n",
    "    \"\"\"\n",
    "    xs = torch.from_numpy(xs).float()\n",
    "    ys = torch.from_numpy(ys).long()\n",
    "    if gpu:\n",
    "        xs = xs.cuda()\n",
    "        ys = ys.cuda()\n",
    "    return Variable(xs), Variable(ys)\n",
    "\n",
    "\n",
    "def compute_loss(criterion, outputs, labels, batch_size, num_colours):\n",
    "    \"\"\"\n",
    "    Helper function to compute the loss. Since this is a pixelwise\n",
    "    prediction task we need to reshape the output and ground truth\n",
    "    tensors into a 2D tensor before passing it in to the loss criteron.\n",
    "\n",
    "    Args:\n",
    "      criterion: pytorch loss criterion\n",
    "      outputs (pytorch tensor): predicted labels from the model\n",
    "      labels (pytorch tensor): ground truth labels\n",
    "      batch_size (int): batch size used for training\n",
    "      num_colours (int): number of colour categories\n",
    "    Returns:\n",
    "      pytorch tensor for loss\n",
    "    \"\"\"\n",
    "\n",
    "    loss_out = outputs.transpose(1, 3) \\\n",
    "        .contiguous() \\\n",
    "        .view([batch_size * 32 * 32, num_colours])\n",
    "    loss_lab = labels.transpose(1, 3) \\\n",
    "        .contiguous() \\\n",
    "        .view([batch_size * 32 * 32])\n",
    "    return criterion(loss_out, loss_lab)\n",
    "\n",
    "\n",
    "def run_validation_step(cnn, criterion, test_grey, test_rgb_cat, batch_size,\n",
    "                        colour, plotpath = None):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    losses = []\n",
    "    for i, (xs, ys) in enumerate(get_batch(test_grey,\n",
    "                                           test_rgb_cat,\n",
    "                                           batch_size)):\n",
    "        images, labels = get_torch_vars(xs, ys, gpu)\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        val_loss = compute_loss(criterion,\n",
    "                                outputs,\n",
    "                                labels,\n",
    "                                batch_size = batch_size,\n",
    "                                num_colours = num_colours)\n",
    "        losses.append(val_loss.data[0])\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1, keepdim = True)\n",
    "        total += labels.size(0) * 32 * 32\n",
    "        correct += (predicted == labels.data).sum()\n",
    "\n",
    "    if plotpath:  # only plot if a path is provided\n",
    "        plot(xs, ys, predicted.cpu().numpy(), colours, plotpath)\n",
    "\n",
    "    val_loss = np.mean(losses)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Our simplified implemented of nn.Conv2d module for 2D convolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding = None):\n",
    "        super(MyConv2d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        if padding is None:\n",
    "            self.padding = kernel_size // 2\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        self.weight = nn.parameter.Parameter(torch.Tensor(\n",
    "            out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.parameter.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels * self.kernel_size * self.kernel_size\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.weight, self.bias, padding = self.padding)\n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel, num_filters, num_colours):\n",
    "        super(CNN, self).__init__()\n",
    "        padding = kernel // 2\n",
    "\n",
    "        ############### YOUR CODE GOES HERE ###############\n",
    "        self.downconv1 = nn.Sequential(\n",
    "            MyConv2d(1, num_filters, kernel_size = kernel, padding = padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            MyConv2d(num_filters, num_filters * 2, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters * 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.rfconv = nn.Sequential(\n",
    "            MyConv2d(num_filters * 2, num_filters * 2, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.BatchNorm2d(num_filters * 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.upconv1 = nn.Sequential(\n",
    "            MyConv2d(num_filters * 2, num_filters, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.Upsample(scale_factor = 2),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU())\n",
    "        self.upconv2 = nn.Sequential(\n",
    "            MyConv2d(num_filters, num_colours, kernel_size = kernel, padding = padding),\n",
    "            nn.Upsample(scale_factor = 2),\n",
    "            nn.BatchNorm2d(num_colours),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.finalconv = MyConv2d(num_colours, num_colours, kernel_size = kernel)\n",
    "        ###################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out1 = self.downconv1(x)\n",
    "        self.out2 = self.downconv2(self.out1)\n",
    "        self.out3 = self.rfconv(self.out2)\n",
    "        self.out4 = self.upconv1(self.out3)\n",
    "        self.out5 = self.upconv2(self.out4)\n",
    "        self.out_final = self.finalconv(self.out5)\n",
    "        return self.out_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, kernel, num_filters, num_colours):\n",
    "        super(UNet, self).__init__()\n",
    "        padding = kernel // 2\n",
    "\n",
    "        ############### YOUR CODE GOES HERE ###############\n",
    "        self.downconv1 = nn.Sequential(\n",
    "            MyConv2d(1, num_filters, kernel_size = kernel, padding = padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            MyConv2d(num_filters, num_filters * 2, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters * 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.rfconv = nn.Sequential(\n",
    "            MyConv2d(num_filters * 2, num_filters * 2, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.BatchNorm2d(num_filters * 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.upconv1 = nn.Sequential(\n",
    "            MyConv2d(num_filters * 2, num_filters, kernel_size = kernel,\n",
    "                      padding = padding),\n",
    "            nn.Upsample(scale_factor = 2),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU())\n",
    "        self.upconv2 = nn.Sequential(\n",
    "            MyConv2d(num_filters, num_colours, kernel_size = kernel, padding = padding),\n",
    "            nn.Upsample(scale_factor = 2),\n",
    "            nn.BatchNorm2d(num_colours),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.finalconv = MyConv2d(num_colours, num_colours, kernel_size = kernel)\n",
    "        ###################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############### YOUR CODE GOES HERE ###############\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "\n",
    "        self.out1 = self.downconv1(x)\n",
    "        print(\"out 1: {}\".format(self.out1.shape))\n",
    "\n",
    "        self.out2 = self.downconv2(self.out1)\n",
    "        print(\"out 2: {}\".format(self.out2.shape))\n",
    "\n",
    "        self.out3 = self.rfconv(self.out2)\n",
    "        print(\"out 3: {}\".format(self.out3.shape))\n",
    "\n",
    "        self.out4 = self.upconv1(self.out3)\n",
    "        print(\"out 4: {}\".format(self.out4.shape))\n",
    "        # self.out4 = torch.cat((self.out4, self.out2), 1)\n",
    "\n",
    "        self.out5 = self.upconv2(self.out4)\n",
    "        print(\"out 5: {}\".format(self.out5.shape))\n",
    "        # self.out5 = torch.cat((self.out5, self.out1))\n",
    "\n",
    "        self.out_final = self.finalconv(self.out5)\n",
    "        print(\"out final: {}\".format(self.out_final.shape))\n",
    "        # self.out_final = torch.cat((self.out_final, x))\n",
    "\n",
    "        return self.out_final\n",
    "        ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "data/cifar-10-batches-py.tar.gz\n",
      "Transforming data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum number of threads to prevent crash in Teaching Labs\n",
    "torch.set_num_threads(5)\n",
    "\n",
    "# Numpy random seed\n",
    "npr.seed(seed)\n",
    "\n",
    "# LOAD THE COLOURS CATEGORIES\n",
    "colours = np.load(colours)[0]\n",
    "num_colours = np.shape(colours)[0]\n",
    "\n",
    "# LOAD THE MODEL\n",
    "if model == \"CNN\":\n",
    "    cnn = CNN(kernel, num_filters, num_colours)\n",
    "elif model == \"UNet\":\n",
    "    cnn = UNet(kernel, num_filters, num_colours)\n",
    "else:  # model == \"DUNet\":\n",
    "    cnn = DilatedUNet(kernel, num_filters, num_colours)\n",
    "\n",
    "# LOSS FUNCTION\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = learn_rate)\n",
    "\n",
    "# DATA\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "\n",
    "print(\"Transforming data...\")\n",
    "train_rgb, train_grey = process(x_train, y_train)\n",
    "train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
    "test_rgb, test_grey = process(x_test, y_test)\n",
    "test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "# Create the outputs folder if not created already\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "\n",
    "# Run validation only\n",
    "if valid:\n",
    "    if not checkpoint:\n",
    "        raise ValueError(\"You need to give trained model to evaluate\")\n",
    "\n",
    "    print(\"Loading checkpoint...\")\n",
    "    cnn.load_state_dict(\n",
    "        torch.load(checkpoint, map_location = lambda storage, loc: storage))\n",
    "    img_path = \"outputs/eval_%s.png\" % model\n",
    "    val_loss, val_acc = run_validation_step(cnn,\n",
    "                                            criterion,\n",
    "                                            test_grey,\n",
    "                                            test_rgb_cat,\n",
    "                                            batch_size,\n",
    "                                            colours,\n",
    "                                            img_path)\n",
    "    print('Evaluating Model %s: %s' % (model, checkpoint))\n",
    "    print('Val Loss: %.4f, Val Acc: %.1f%%' % (val_loss, val_acc))\n",
    "    print('Sample output available at: %s' % img_path)\n",
    "    exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training ...\n",
      "x: torch.Size([10, 1, 32, 32])\n",
      "out 1: torch.Size([10, 32, 16, 16])\n",
      "out 2: torch.Size([10, 64, 8, 8])\n",
      "out 3: torch.Size([10, 64, 8, 8])\n",
      "out 4: torch.Size([10, 32, 16, 16])\n",
      "out 5: torch.Size([10, 24, 32, 32])\n",
      "out final: torch.Size([10, 24, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Python2.7/lib/python2.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d1e9e5d16ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# plot training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "print(\"Beginning training ...\")\n",
    "if gpu:\n",
    "    cnn.cuda()\n",
    "start = time.time()\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "for epoch in range(epochs):\n",
    "    # Train the Model\n",
    "    cnn.train()  # Change model to 'train' mode\n",
    "    losses = []\n",
    "    for i, (xs, ys) in enumerate(get_batch(train_grey,\n",
    "                                           train_rgb_cat,\n",
    "                                           batch_size)):\n",
    "        images, labels = get_torch_vars(xs, ys, gpu)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        loss = compute_loss(criterion,\n",
    "                            outputs,\n",
    "                            labels,\n",
    "                            batch_size = batch_size,\n",
    "                            num_colours = num_colours)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data[0])\n",
    "\n",
    "    # plot training images\n",
    "    if plot:\n",
    "        _, predicted = torch.max(outputs.data, 1, keepdim = True)\n",
    "        plot(xs, ys, predicted.cpu().numpy(), colours,\n",
    "             'outputs/train_%d.png' % epoch)\n",
    "\n",
    "    # plot training images\n",
    "    avg_loss = np.mean(losses)\n",
    "    train_losses.append(avg_loss)\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Epoch [%d/%d], Loss: %.4f, Time (s): %d' % (\n",
    "        epoch + 1, epochs, avg_loss, time_elapsed))\n",
    "\n",
    "    # Evaluate the model\n",
    "    cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "\n",
    "    outfile = None\n",
    "    if plot:\n",
    "        outfile = 'outputs/test_%d.png' % epoch\n",
    "\n",
    "    val_loss, val_acc = run_validation_step(cnn,\n",
    "                                            criterion,\n",
    "                                            test_grey,\n",
    "                                            test_rgb_cat,\n",
    "                                            batch_size,\n",
    "                                            colours,\n",
    "                                            outfile)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    valid_losses.append(val_loss)\n",
    "    valid_accs.append(val_acc)\n",
    "    print('Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %d' % (\n",
    "        epoch + 1, epochs, val_loss, val_acc, time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot training curve\n",
    "# plt.plot(train_losses, \"ro-\", label = \"Train\")\n",
    "# plt.plot(valid_losses, \"go-\", label = \"Validation\")\n",
    "# plt.legend()\n",
    "# plt.title(\"Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.savefig(\"outputs/training_curve.png\")\n",
    "\n",
    "# if checkpoint:\n",
    "#     print('Saving model...')\n",
    "#     torch.save(cnn.state_dict(), checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print(a.transpose((0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
